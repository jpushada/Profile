# Profile
This repository give brief on my professional work arounds
# 👩‍💻 Jhansi Pushadapu

**Data Scientist | Solution Architect | Senior Data Engineer**

📍 Hyderabad, India  
📧 jhansip6990@gmail.com  
📞 +91 8978744319  

---

## 🚀 About Me

Experienced Data Scientist and Solution Architect with 12+ years of expertise in delivering enterprise-grade AI/ML, Data Engineering, and Cloud-based solutions. I specialize in building scalable ETL pipelines, deploying NLP and predictive models, and securing systems with modern authentication protocols. Passionate about using data to drive business value and innovation.

---

## 🧠 Expertise Summary

- **AI/ML & NLP**: Predictive modeling, Deep Learning, Text Mining, ICD-10 Code Mapping  
- **Data Engineering**: Databricks, DataStage, Spark, Python, Azure Data Factory  
- **Cloud Platforms**: Microsoft Azure (ADF, ADLS, Databricks), AWS (EMR, S3, Glue)  
- **Authentication & Security**: OAuth 2.0, Azure AD, Azure Defender  
- **Big Data Ecosystem**: Spark, Hive, HDFS, Kafka, Cassandra  
- **Reporting**: Power BI, Tableau  
- **CI/CD & DevOps**: Azure DevOps, Jenkins, GitHub  
- **Data Formats**: Parquet, JSON, CSV

---

## 💼 Professional Experience

### 🔹 Optum (Nov 2021 – Present)  
**Role**: Data Scientist & Solution Architect  

- Designed and deployed ML models with a focus on NLP, deep learning, and predictive analytics.  
- Developed secure, scalable ETL pipelines using Azure Data Factory and Databricks.  
- Integrated OAuth 2.0 and Azure AD for secure API authentication and access control.  
- Managed cloud data migrations using Python and Azure services, including ADLS and Databricks Delta.  
- Ensured robust monitoring and vulnerability management using Azure Defender.

---

### 🔹 Advance Auto Parts (via TEK Systems) (Mar 2021 – Nov 2021)  
**Role**: Senior Data Engineer  

- Led the design of ETL pipelines using DataStage and Databricks.  
- Migrated legacy data platforms to AWS using EMR, Scala, and Python.  
- Deployed ML models for predictive analytics and improved operational decision-making.  
- Built OAuth-secured APIs for safe and structured data exchange.

---

### 🔹 IBM India Pvt Ltd (Apr 2013 – Mar 2021)  
**Role**: Data Engineer  

- Built complex ETL workflows in DataStage, supporting enterprise-scale transformations.  
- Created Power BI dashboards for real-time insights.  
- Deployed Spark jobs for high-speed data processing on Azure.  
- Contributed to secure API integration with OAuth protocols.

---

## 📂 Key Projects

### ✅ United AI Studio (Optum)
- Automated vulnerability management for ML models using Azure Defender and Databricks.

### ✅ eCAC – Medical Coding (Optum)
- Built NLP models to map patient diagnosis data to ICD-10 codes.

### ✅ Life Sciences DVP Tool (Optum)
- Automated pipeline executions using AWS Step Functions and Databricks.

### ✅ NHI Migration (Optum)
- Led secure cloud migration from on-prem to Azure, with OAuth-secured pipelines.

### ✅ Intrepid – Data Migration (Advance Auto Parts)
- Migrated and transformed large datasets from DB2/Oracle to AWS cloud.

---

## 🧪 Technical Toolkit

- **Languages**: Python, PySpark, Scala, SQL  
- **Cloud**: Azure, AWS (EMR, Glue, S3), Azure DevOps  
- **ETL Tools**: IBM DataStage, Databricks  
- **ML Tools**: Scikit-learn, Azure ML, Deep Learning (ANN, CNN)  
- **Big Data**: Hive, Spark, Kafka, HDFS  
- **Databases**: Oracle, MySQL, Snowflake, SQL Server, MongoDB  
- **Schedulers**: Jenkins, UC4, Control M, Tivoli  
- **Visualization**: Power BI, Tableau

---

## 🏆 Achievements

- **2 Patent Submissions** for AI/ML-based innovation in healthcare data processing.  
- Architected and implemented Medallion architecture for real-time data analytics.  
- Built secure, production-grade ML systems deployed at scale across healthcare use cases.

---

## 📫 Let's Connect

- Email: **jhansip6990@gmail.com**  
- Mobile: **+91 8978744319**  
- Location: **Hyderabad, India**  
- GitHub: https://github.com/jpushada
- LinkedIn: (https://www.linkedin.com/in/jhansi-p-60478b214/)

---

Thank you for visiting my profile. I'm always open to collaborating on innovative data and AI projects!
